from sqlalchemy.exc import SQLAlchemyError
from sqlalchemy.orm import sessionmaker
from sqlalchemy import text
from annoy import AnnoyIndex
from datetime import datetime
import pandas as pd
import pickle
import math
import uuid

from util.database import engine


def db_insert(session, message_id, chat_id, client_message_id, room_id, sent_at, user_id, message, current_time, duplicate_count, original_id):
    try:
        session.execute(text(
            """
            INSERT INTO mydb_TbKaFeed 
            (id, chatId, clientMessageId, roomId, sentAt, userId, message, createdDate, modifiedDate, duplicate_count, original_message_id, deleted)
            VALUES (:id, :chatId, :clientMessageId, :roomId, :sentAt, :userId, :message, :createdDate, :modifiedDate, :duplicate_count, :original_message_id, :deleted)
            """
        ), {
            "id": message_id,
            "chatId": chat_id,
            "clientMessageId": client_message_id,
            "roomId": room_id,
            "sentAt": sent_at,
            "userId": user_id,
            "message": message,
            "createdDate": current_time,
            "modifiedDate": current_time,
            "duplicate_count": duplicate_count,
            "original_message_id": original_id,
            "deleted": "N"
        })
        session.commit()
    except Exception as e:
        session.rollback()
        print(f"ë°ì´í„° ì‚½ì… ì¤‘ ë¬¸ì œ ë°œìƒ: {e}")
    finally:
        print("ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì‚½ì…ë˜ì—ˆìŠµë‹ˆë‹¤.")
        session.close()


def process_message():
    # TF-IDF ë²¡í„°í™” ëª¨ë¸ ë¡œë“œ
    with open('./artifacts/tfidf_vectorizer.pkl', 'rb') as f:
        tfidf_vectorizer = pickle.load(f)

    # Annoy ì¸ë±ìŠ¤ ë¡œë“œ
    f = len(tfidf_vectorizer.get_feature_names_out())
    annoy_index = AnnoyIndex(f, 'angular')
    annoy_index.load('./artifacts/annoy_index.ann')

    # ê¸°ì¡´ ë©”ì‹œì§€ ë¡œë“œ
    with engine.connect() as connection:
        df = pd.read_sql_table('mydb_TbKaFeed', con=connection)

    user_input = """[D-2]ğŸ«¢í•˜ë²„ë“œë³´ë‹¤ ë“¤ì–´ê°€ê¸° ì–´ë µë‹¤ëŠ” ë¯¸ë„¤ë¥´ë°” ëŒ€í•™ì˜ êµìœ¡ì´ í•œë™ì— ë“¤ì–´ì˜¨ë‹¤ê³ â‰ï¸ğŸ«¢"""
    user_vector = tfidf_vectorizer.transform([user_input]).toarray().flatten()

    n_similar = 1
    similar_items, distances = annoy_index.get_nns_by_vector(user_vector, n_similar, include_distances=True)

    threshold = 1.1
    chat_id = 12345678901234567
    client_message_id = 12345678901234567
    room_id = 12345678901234567
    sent_at = 1609459200
    user_id = 12345678901234567

    for idx in range(len(distances)):
        Session = sessionmaker(bind=engine)
        session = Session()

        message_id = str(uuid.uuid4()).replace('-', '')
        current_time = datetime.now()

        if distances[idx] < threshold:
            original_id = df.iloc[similar_items[idx]]['original_message_id']
            if original_id is None:
                original_id = df.iloc[similar_items[idx]]['id']
            max_duplicate_count = df[df['original_message_id'] == original_id]['duplicate_count'].max()
            new_duplicate_count = max_duplicate_count + 1

            if math.isnan(new_duplicate_count):
                new_duplicate_count = 0

            db_insert(session, message_id, chat_id, client_message_id, room_id, sent_at, user_id, user_input,
                      current_time, new_duplicate_count, original_id)
            print(f"ì¤‘ë³µëœ ë©”ì‹œì§€ì…ë‹ˆë‹¤. (ì›ë³¸ ë©”ì‹œì§€ ID: {original_id}, ì¤‘ë³µ íšŸìˆ˜: {new_duplicate_count})")

        else:
            db_insert(session, message_id, chat_id, client_message_id, room_id, sent_at, user_id, user_input,
                      current_time, 0, None)
            print("ì¤‘ë³µë˜ì§€ ì•Šì€ ìƒˆë¡œìš´ ë©”ì‹œì§€ì…ë‹ˆë‹¤.")


if __name__ == "__main__":
    process_message()